# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Summary
**In 1-2 sentences, explain the problem statement: e.g "This dataset contains data about... we seek to predict..."**
The data is related with direct marketing campaigns (phone calls) of a Portuguese banking institution. The classification goal is to predict if the client will subscribe a term deposit (variable y).
More information here https://archive.ics.uci.edu/ml/datasets/bank+marketing

**In 1-2 sentences, explain the solution: e.g. "The best performing model was a ..."**
The best performing model was a AutoML model with StandardScalerWrapper and XGBoostClassifier as algorithm. The accuracy was 0.98240. It must be noted that the label data is imbalanced thus a better metric to use would have been the f1 score.

## Scikit-learn Pipeline
**Explain the pipeline architecture, including data, hyperparameter tuning, and classification algorithm.**
The scikit learn pipeline was composed of a .py file and a hyperparameter tuning notebook. The .py file downloads the data, cleans the data (one-hot encoding, transforms text in to discrete features). It then splits data into a train-test split, fits a logistic regression and logs the accuracy. The notebook calls the .py file with different hyperparameter configurations.

**What are the benefits of the parameter sampler you chose?**
RandomParameterSampling is often better compared to Gridsampling, since often there are only a couple of hyperparameters that really matter. With grid sampling that means that there are multiple runs executed with the same value for the relevant hyperparameters, varying the hyperparameters that do not matter. With random sampling you end up with more sample points from your relevant hyperparameters. Karpathy once mentioned this in his computer vision course.
Now baysian sampling works probably even better, but wanted to keep it simple for this exercise.

**What are the benefits of the early stopping policy you chose?**
This saves time and compute. If you don't improve anymore, it's better to stop since subsequent runs are just wasted. Now the trick is to know when you are not improving anymore. With a 



## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**

## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**
Basically the AutoML model performed much better. This is because AutoML has a couple of advantages: 1) it tries out many different models 2) these models are more advanced than Logistic model 3) The numeric features are scaled, which does not happen in the Logistic pipeline.

## Future work
**What are some areas of improvement for future experiments? Why might these improvements help the model?**
Use other hyperparameters for the logistic classifier, preprocess the data

## Proof of cluster clean up
I did it in the code with the delete method. However, I don't fully understand why this should be done, if I have a compute cluster with min_nodes = 0, this does not incur any costs, so isn't it useful to keep and re-use it? I do understand Azure counts the nodes in your quota even if you don't use them.
